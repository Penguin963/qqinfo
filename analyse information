import re
import os
from pyhanlp import *
from pyltp import Segmentor
from pyltp import Postagger

class LTP(object):
    def __init__(self):
        cws_model_path = os.path.join(os.path.dirname(__file__), 'cws.model')  # 分词模型路径，模型名称为`cws.model`
        pos_model_path = os.path.join(os.path.dirname(__file__), 'pos.model')  # 词性标注模型路径，模型名称为`pos.model`
        self.segmentor = Segmentor()  # 初始化实例
        self.segmentor.load(cws_model_path) # 加载模型
        self.postagger = Postagger()  # 初始化实例
        self.postagger.load(pos_model_path)  # 加载模型

    # 分词
    def segment(self, text):
        words = list(self.segmentor.segment(text))
        return words

    # 词性标注
    def postag(self, words):
        postags = list(self.postagger.postag(words))
        return postags

    # 获取文本中的时间
    def get_time(self, text):

        # 开始分词及词性标注
        words = self.segment(text)
        postags = self.postag(words)

        time_lst = []

        i = 0
        for tag, word in zip(postags, words):
            if tag == 'nt':
                j = i
                while postags[j] == 'nt' or words[j] in ['至', '到']:
                    j += 1
                time_lst.append(''.join(words[i:j]))
            i += 1

        # 去重子字符串的情形
        remove_lst = []
        for i in time_lst:
            for j in time_lst:
                if i != j and i in j:
                    remove_lst.append(i)

        text_time_lst = []
        for item in time_lst:
            if item not in remove_lst:
                text_time_lst.append(item)

        # print(text_time_lst)
        return text_time_lst

    # 释放模型
    def free_ltp(self):
        self.segmentor.release()
        self.postagger.release()


def fac(f,s):  # 消除掉原地点中的/n等标识符
    for words in s:
        if words == '/' or (words >= 'a' and words <= 'z'):
            s=s.replace(words, '')
    f += s + '\t'
    return f

def mini_space(f, content):

    flag=0

    #提取网址
    res = re.compile(r'((http|ftp|https)://)(([a-zA-Z0-9\._-]+\.[a-zA-Z]{2,6})|([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}))(:[0-9]{1,4})*(/[a-zA-Z0-9\&%_\./-~-]*)?')  # 匹配URL地址
    a = re.findall(res, content)
    for list in a:
        s = ''
        for words in list:
            s += words
        f += '网址:' + s + '\t'
        flag=1

    segment = HanLP.newSegment().enableNameRecognize(True)
    term_list = segment.seg(content)
    list2 = [str(i) for i in term_list]
    list3 = ''.join(list2)


    res = re.compile(r'在/p([\u2E80-\u9FFF]+?)/[nf]([\u2E80-\u9FFF]+?)/[vm](.+?)/n')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f = fac(f, s)
        flag = 1

    res = re.compile(
        r'在/p([\u2E80-\u9FFF]+?)/t([\u2E80-\u9FFF]+?)/vn([\u2E80-\u9FFF]+?)/ude1(.+?)/n')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(
        r'在/p([\u2E80-\u9FFF]+?)/t([\u2E80-\u9FFF]+?)/v([\u2E80-\u9FFF]+?)/ude1(.+?)/n')  # ['在/p上次/t站队/v的/ude1位置/n']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'在/p([\u2E80-\u9FFF]+?)/ng([\u2E80-\u9FFF]+?)/[vm](.+?)/n')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'在/p(\d+?)/m([\u2E80-\u9FFF]+?)/v')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'在/p(\d+?)/m([\u2E80-\u9FFF]+?)/n')  # ['在/p9201/m照常进行/n']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'在/p【/w([\u2E80-\u9FFF]+?)/nz([\u2E80-\u9FFF]+?)/qv】')  # ['露天电影/nz场']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'在/p【/w([\u2E80-\u9FFF]+?)/nz(.*?)([\u2E80-\u9FFF]+?)/n】')  # ['露天电影/nz场']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'在/p([\u2E80-\u9FFF]+?)/nz([\u2E80-\u9FFF]+?)/n')  # ['号/nz楼/n']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'在/p([\u2E80-\u9FFF]+?)/nz([\u2E80-\u9FFF]+?)/a(.+?)/n')  # ['在/p十楼/nz大/a会议室/n']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'到/v([\u2E80-\u9FFF]+?)/ng([\u2E80-\u9FFF]+?)/vg([\u2E80-\u9FFF]+?)(.*?)/n')  # ['佑铭/vg训练场']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'到/v([\u2E80-\u9FFF]+?)/rr([\u2E80-\u9FFF]+?)/nis')  # ['我办公室']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'于/p([\u2E80-\u9FFF]+?)/nnt([\u2E80-\u9FFF]+?)/nis')  # ['大学生活动中心']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'登录/v([\u2E80-\u9FFF]+?)/vt([\u2E80-\u9FFF]+?)(.*?)/n')  # ['选课/vi系统']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'去/vf(.+?)/m换')  # ['东/f十六']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'地点/n(\d+?)/m')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'地点/n：/w(\d+?)/m(.*?)。')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'地点/n为/p：/w(\d+?)/m(.*?)/nx(\d+?)/m、*?。')  # ['9-11、9-12、9-13']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'地点/n：/w([\u2E80-\u9FFF]+?)/ntu([\u2E80-\u9FFF]+?)(.*?)/n')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'地点/n为/p(\d+?)/m')  # ['今天/t训练/vn的/ude1地方']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'地点/n为/p([\u2E80-\u9FFF]+?)/nz([\u2E80-\u9FFF]+?)(.*?)/n')  # ['地点/n为/p九号/nz楼/n机房/n']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(
        r'地点/n是/vshi([\u2E80-\u9FFF]+?)/nnt([\u2E80-\u9FFF]+?)(.*?)/n')  # ['地点/n是/vshi大学生/nnt活动中心/nis五/m楼/n']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'考试/vn教室/n安排/v为/p(.*?)。')  # [('1006', '办公室')]
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'(\d+?)/m办公室')  # [('1006', '办公室')]
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'办公室/nis(\d+?)/m([\u2E80-\u9FFF]+?)/q(\d+?)/m')  # [/w办公室/nis9/m号楼/q1029/m室/n，]
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1

    res = re.compile(r'(\d+?)/m会议室')  # [('1005会议室')]
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f = fac(f, s)
        flag = 1

    res = re.compile(r'(\d+?)/m机房')  # ['1129机房']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f=fac(f, s)
        flag = 1
    '''
    res = re.compile(r'(\d+?)/m教室')  # ['1129机房']
    a = re.findall(res, list3)
    for list in a:
        s = ''
        for words in list:
            s += words
        f = fac(f, s)
        flag = 1

    if flag==0:
        f += '暂无\t' '''
    return f

def mini_name(f,content):
    flag = 0;
    res=re.compile(r'([\u4e00-\u9fa5]+?)的同学')
    a = re.findall(res, content)
    for list in a:
        s = ''
        for words in list:
            s += words
        f += s+'的同学\t'
        flag=1;

    if flag==0:
        f += '全体同学\t'
    return  f


def find_message(filename):
    f = open(filename, 'r', encoding='utf-8')
    txt = f.read()
    f.close()
    fh2txt=''
    re_pat = r'20[\d-]{8}\s[\d:]{7,8}\s+[^\n]+(?:\d{5,11}|@\w+\.[comnetcn]{2,3})\)'#正则表达式
    log_title_arr = re.findall(re_pat, txt)  # 记录头数组['2016-06-24 15:42:52  张某(40**21)',…]
    log_content_arr = re.split(re_pat, txt)  # 把符合正则表达式的字符串作为分隔符，得到内容的列表，记录具体内容数组
    log_content_arr.pop(0) #移除列表中第一个元素
    l1 = len(log_title_arr)
    l2 = len(log_content_arr)
    #fh1=open('F:/result1.txt','w',encoding='utf-8') 把初步结果写进文件
    #fh2=open('F:/result2-1.txt','w',encoding='utf-8') #把进一步的结果写进文件 输出文件位置
    #fh1.write('记录头数: %d\n记录内容: %d' % (l1, l2)+'\n')
    #fh2.write('记录头数: %d\n记录内容: %d' % (l1, l2)+'\n')
    fh2txt += '记录头数: %d\n记录内容: %d' % (l1, l2)+'\n'
    log_format = ''
    ltp = LTP()
    for i in range(0, l1):
        title = log_title_arr[i]  # 记录头
        content = log_content_arr[i].strip()  # 删记录内容首尾空白字符
        if content.find("@全体成员")!=-1:
            ltp = LTP()
            time_list = ltp.get_time(content)  #获取这一段文本的时间信息 list型
            time_str = ",".join(time_list) #转为str
            ltp.free_ltp()
            sentence = HanLP.parseDependency(content) ## 依存句法分析str型
            #fh1.write(title+'\n')
            #fh1.write(content+'\n\n')
            #fh2.write(title+'\n')
            fh2txt += title+'\n'
            if time_str.strip()=='': #写入时间信息
                #fh2.write('时间: '+'暂无\n')
                fh2txt += '时间: '+'暂无\n'
            else:
                fh2txt += '时间: '+time_str+'\n'
                #fh2.write('时间: '+time_str+'\n')
            
            fh2txt += '地点:'    #地点
            fh2txt = mini_space(fh2txt,content)
            fh2txt +='\n'
            
            fh2txt += '人物:'    #人物
            fh2txt = mini_name(fh2txt,content)
            fh2txt += '\n'
            
            fh2txt += '事件:'   #把具有动宾关系的词分离出来(事件信息)
            for word in sentence.iterator(): 
                if word.DEPREL=='动宾关系' and word.HEAD.LEMMA!='@':
                    fh2txt += "%s->%s" % (word.HEAD.LEMMA, word.LEMMA )+'， '
                    #fh2.write("%s->%s" % (word.HEAD.LEMMA, word.LEMMA )+',')
            fh2txt += '\n\n'
            #fh2.write('\n\n')
    #fh1.close()
    return fh2txt


#filename = input("请输入源文件位置：");
#find_message(filename) #这里是 F:/2018.txt
